<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width initial-scale=1.0">
    <link rel="icon" href="https://image.flaticon.com/icons/png/512/65/65000.png">

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous" />
    <link rel="stylesheet" href="styles.css" />

    <title>Surveillance Tech</title>



</head>

<body>
    <div class="surv-tech-header">
        <div class="container">
            <div class="row py-5">
                <div class="col-12 py-5 text-center">
                    <h1 class="mt-5 mx-3 text-white display-1">Surveillance technology is here. </h1>
                    <h1 class="font-weight-bold text-light">What does this mean for you?</h1>
                </div>
            </div>
        </div>
    </div>

    <section class="mx-auto mt-5 col-12 col-lg-8">
        <!-- feeling good about this section. marking it as done. please feel free to add edits -->
        <h3>History was made this summer <small class="text-muted d-block">When a man was arrested based on facial recognition alone</small></h3>
        <div class="row mt-3">
            <div class="col-12 col-lg-6">
                <p>In June 2020, the <a href="https://www.npr.org/2020/06/24/882683463/the-computer-got-it-wrong-how-facial-recognition-led-to-a-false-arrest-in-michig" target="blank">first arrest</a> using only evidence from Facial Recognition (FR) technology
                    occurred in Detroit, Michigan. Five watches were stolen from a Shinola store. The police reviewed security footage from the incident and zoomed in on the perpetrator to capture an image of him. Despite the shoddy image quality, they ran it through the police
                    department's FR software, which provided them with a potential suspect. Officers pursued this suspect without any further investigation. Police arrived at this man's house and arrested him in his front yard without questioning; he was not provided any information about what was
                    happening as his family and neighbors stood by and watched. He was detained for 30 hours and was eventually released on bail until his court hearing.</p>
                <p>The man arrested lived 25 miles north of Detroit, had a solid alibi, and didn't own any of the clothing that the person in the security footage was wearing. Without the FR software's output stating he was a match, there were no indications
                    that he could have possibly committed this crime.
                </p>
            </div>
            <div class="col-12 col-lg-6"><img class="img-fluid" src="images/wrongful_arrest_probe.png" /></div>
        </div>

        <p>The charges were later dropped due to insufficient evidence. However, a person was still wrongfully accused of and arrested for a crime based on erroneous identification from security footage analysis. While some may argue that FR technology
            is simply a tool used to aid police in finding leads, that explanation is insufficient when innocent people's lives and dignities are on the line. The Michigan State Police's Investigative Lead Report, shown above, clearly states that the document contains a
            <i>possible</i> lead to be investigated, and that it is not probable cause for arrest. No matter how clearly stated, bolded, and underlined this guideline is, it was not followed.</p>

        <p>This software is still presently being used in Detroit.</p>



    </section>
    <section class="mx-auto mt-5 col-12 col-lg-8">
        <h3>How could this wrongful arrest happen? <small class="text-muted d-block">Surveillance technology.</small>
        </h3>
        <p>Surveillance technology takes many forms. Visual, audio, textual, biometric, or location data can all be collected by technology with the purpose to surveil us. In the case discussed above in Detroit, this
            initiative is called Project Green Light. </p>
        <h4>Project Green Light</h4>
        <p><a href="https://detroitmi.gov/departments/police-department/project-green-light-detroit" target="blank">Project Green Light</a> is a community policing effort in the city of Detroit, Michigan. Cameras are installed throughout the city at designated
            locations and have a direct feed to the Detroit Police. This system has been marketed to the citizens of Detroit as a way to prevent crime in the name of "public safety".</p>
        <p>Project Green Light partners with local businesses to set up cameras at their locations with accompanying Project Green Light signs. The cameras allow the Detroit Police Department to have a live stream of the city from many different viewpoints,
            and in turn, offer the businesses extra support from the police and a potential crime deterrent with the branded sign. Police <a href="http://video.detroitmi.gov/CablecastPublicSite/show/5963?channel=3." target="blank">“virtually patrol”</a>            each affiliated location once a day and physically patrol around
            <a href="https://detroitmi.gov/webapp/project-green-light-map" target="blank">184 affiliated locations</a> each day.</p>
        <p>Like <a href="https://www.acslaw.org/expertforum/mass-surveillance-and-black-legal-history/" target="blank">many police surveillance projects before it</a>,
            it appears that Project Green Light disproportionately surveils Black residents of Detroit.
            We overlaid a <a href="http://racialdotmap.demographics.coopercenter.org/" target="blank">map</a> of racial demographics in Detroit on top of Project Green Light's <a href="https://detroitmi.gov/webapp/project-green-light-map" target="blank">map</a> of its camera network. Each camera is
            represented by a large dot. Small, color-coded dots denote different race demographics. Note that the cameras are in predominantly Black and Hispanic neighborhoods.</p>


        <div class="row">
            <div class="col-lg">
                <img src="images/Detroit_Green_Light_w_race_overlay.png" class="rounded img-fluid mx-auto p-3" />
            </div>
        </div>

        <p>Surveillance technology and predictive policing largely lead to the increased
            <a href="https://cdt.org/insights/critical-scrutiny-of-predictive-policing-is-a-step-to-reducing-disability-discrimination/" target="blank">
                overpolicing of Black and brown populations</a>,
            which already suffer from discrimination from law enforcement. According to the
            <a href="https://www.vera.org/downloads/publications/for-the-record-unjust-burden-racial-disparities.pdf" target="blank">Vera Institute of Justice</a>,
            even though Black men make up only 13% of the US population, they account for 35% of people incarcerated.
            Furthermore, 1 in 3 Black men born today can expect to be incarcerated in their lifetime.
            For Latino men, it's 1 in 6.
            For white men? It's 1 in 17.
        </p>
        <p>Clearly, the placement of these cameras in majority Black and Hispanic neighborhoods (according to US Census data)
            means Project Green Light has significant potential to contribute to this systemic overpolicing problem.</p>


        <h4>Facial Recognition Technology</h4>
        <p>FR technology is a part of Project Green Light. The project uses a <a href="https://www.freep.com/story/news/local/michigan/2019/03/11/michigan-state-police-facial-recognition-database/3102139002/" target="blank">database</a> containing 8 million
            criminal images and 32 million DMV images. Almost every resident of Michigan is represented in this database. <b>You are likely represented in a database just like this without your knowledge and consent.</b>
        </p>
        <p>There are no standards that FR technology has to meet to be released on the market. This means that this technology can identify people incorrectly 98% of the time and still be considered a reliable tool for law enforcement. In fact, this is
            <a href="https://www.cnet.com/news/facial-recognition-software-inaccurate-in-98-of-metropolitan-police-cases-reports/" target="blank">exactly what's happening.</a>
        </p>
        <p>These systems especially fail at correctly <a href="https://www.washingtonpost.com/technology/2019/12/19/federal-study-confirms-racial-bias-many-facial-recognition-systems-casts-doubt-their-expanding-use/" target="blank">identifying people of color</a>,
           — specifically Black people — which is problematic in a city whose population is approximately 80% Black. Under Project Green Light, this FR technology is likely to misidentify the majority of people whose images are captured,
            leading to false charges and arrests that disproportionately affect Black residents of Detroit.
        </p>


        <h5>How FR Tech Works</h5>
        <p>FR technology works by learning highly individualized traits from a large collection of face photos. Such traits can range from the distances between so-called "face landmarks" — e.g. eyes, nose, mouth — to extremely subtle traits expressed on a handful
            of pixels that, in theory, distinguish one person from all others.</p>

        <p class="mx-auto p-2 try-it"><b>Try it yourself:</b> below you can experiment with a webcam-based face tracking widget that works within your browser window. If you allow this page to access your webcam, you can see how it tracks your face with a bounding box. By checking the option "Detect
            Face Landmarks" you can see how it detects the specific traces of your mouth, nose, eyes, and eyebrows, as well as the contour of your face.</p>

        <div class="text-center mb-3">
            <iframe src="https://justadudewhohacks.github.io/face-api.js/webcam_face_tracking" allow="camera https://justadudewhohacks.github.io/" style="height:80%;width:50%;" title="Interactive face tracking"></iframe>
        </div>

        <p>To identify a specific person, FR tech relies on labeled photos. The more photos of an individual, the more accurate the software is. For this reason, uploading labeled photos — or entire albums — to social media substantially improves computers'
            ability to identify specific individuals. For the same reason, the use of a single photo such as the one in a driver's license can lead to inaccurate matches.</p>


        <div class="row">
            <div class="text-center mx-auto col-12 col-lg-6">
                <img src='https://github.com/kjschmidt913/surveillance-tech-guide/blob/master/images/cv_progress.png?raw=true' width='320px' height='320px' />
            </div>
            <div class="col-12 col-lg-6">
                <p>It's worth noting that FR tech has benefited tremendously from recent advances in an area of Machine Learning called "Computer Vision", where computers are taught to recognize real-world entities, more generally, within images. In this
                    graph we can see how much progress has been made on object detection in ImageNet, the most traditional open data set used by the Computer Vision community.</p>

                <p>In 2011, algorithms would miss 25% of objects in ImageNet; four years later, in 2015, this error rate dropped below 5%, which is about how well humans perform in this task. This period coincides with the emergence of Deep Learning, a branch of Machine
                    Learning that leverages ever-greater computing resources and larger data sets to train increasingly accurate models — so long as the data is sufficiently accurate (!).</p>
            </div>
        </div>

        <p>The FR you just tried above is a product of Deep Learning. It was trained on over 14,000 photos manually labeled with bounding boxes and the resulting model is only 190KB.</p>



    </section>

    <section class="mx-auto mt-5 col-12 col-lg-8">
        <h3>This is happening in Detroit. How does it affect me?</h3>
        <p>Surveillance technology is actually implemented all over the country, with very little publicity or oversight. While complete statistics have proven difficult to come by, there are examples of cities in
            <a href="https://www.eff.org/deeplinks/2016/04/here-are-79-policies-california-surveillance-tech-where-are-other-90" target="blank">California</a>,
            <a href="https://www.cityandstateny.com/articles/policy/technology/nyc-force-nypd-reveal-its-secret-surveillance-tech.html" target="blank">New York</a>, <a href="https://www.chicagoreporter.com/high-tech-surveillance-amplifies-police-bias-and-overreach/"
                target="blank">Illinois</a>, as well as partnerships between the FBI and at least 25 states involving some form of FR (see map below). Due to the current regulatory vacuum, there's little transparency in how FR has been effectively used for
            surveillance. We don't know if images of our faces are currently in a database somewhere, or who has access to them.</p>
        <p>Moreover, you don't need to consciously hand over your data to have your face wind up in an FR database — Clearview AI is a facial recognition company that scrapes the web for its face photos. Most notably, the company pulls photos from blogs
            and social media sites like Facebook, Instagram, and YouTube, amassing
            <a href="https://www.cnn.com/2020/02/26/tech/clearview-ai-hack" target="blank">more than 3 billion photos</a> without the subjects' knowledge. Clearview AI's CEO
            <a href="https://www.theverge.com/2020/8/26/21402978/clearview-ai-ceo-interview-2400-police-agencies-facial-recognition" target="blank"> recently announced</a> that the company has contracts with more than 2,400 police agencies.</p>
        <p>Last year, hackers were able to
            <a href="https://www.wired.com/story/hackers-stole-traveler-photos-border-agency-database/">
                steal a database of traveler photos</a> from a Border Agency, and the Customs and Border Protection has declined to disclose much information on the extent of this breach and the people impacted by it. This is particularly
            problematic because face photos are unlike any other biometric data: as a very salient trait, way beyond identity theft,  face images can be unprecedentedly effective in retrieving one's digital breadcrumbs. In a world where police officers
            have a history of abusing much less powerful tools
            <a href="https://apnews.com/article/699236946e3140659fff8a2362e16f43">to spy on exes, neighbors, and journalists</a>, this rapid spread of FR tech represents a risk to all citizens.</p>

    </section>

    <section class="mx-auto mt-5 col-12 col-lg-8">
        <h3>Is there any legal protection against surveillance tech?</h3>
        <p>While there are no regulations or user protections on the federal level, a few states are taking action to protect their citizens. Checkout the map below to explore where FR technologies are being used in the US, and where people and local governments
            are taking legal action. What's happening in your area?</p>

    </section>
    <section class="col-12">
        <div class=" col-12 mx-auto text-center p-3">
            <iframe src="https://www.banfacialrecognition.com/map/" style="height:80%;width:80%;" title="Facial recognition surveillance in the United States"></iframe>
        </div>
    </section>

    <section class="mx-auto mt-5 col-12 col-lg-8">
        <h3>What can I do as a regular citizen to protect my community?</h3>
        <p>We may feel small, but we form the public opinion. If enough people are vocal, we can demand our legislators
            take action and protect our privacy. The right to privacy is critical for everyone, but
            especially for vulnerable communities that already suffer from racial injustice in policing.</p>
        <p>Check out what actions are being taken in your city and state on the map above. You can also sign
            <a href="https://www.banfacialrecognition.com/" target="blank">this petition</a>
            to urge congress to ban the use of FR in law enforcement.</p>
        <p>In the meantime, new tools have started to emerge to help each of us resist FR technology. Recently,
            <a href="https://www.nytimes.com/2020/08/03/technology/fawkes-tool-protects-photos-from-facial-recognition.html" target="blank"> a team at
                the University of Chicago</a> released a desktop app, called Fawkes, that allows anyone to "poison" their own photos by making changes that are imperceptible
            to humans, but destructive to Deep Learning models. If these "poisoned" images are added to
        databases for FR algorithms to learn from, they can
            <a href="https://sandlab.cs.uchicago.edu/fawkes/" target="blank"> confuse the FR algorithm's understanding</a>
            of the patterns that represent a person's face. In other words, your photos can become
            "Trojan horses to deliver that poison to any facial recognition models of you". In this vein, Project Fawkes
            — as in the Guy Fawkes mask — serves as an individual form of resistance while a collective fight for
            regulation is underway.</p>
        <p> The world of FR is evolving, but so is our response to it. As more people learn about the dangers of
            surveillance technology and FR, we can gain more power in our movement to protect ourselves and those we care about.</p>
        <p>The issue of surveillance technology has not been given the attention we believe it deserves, so please share
            this page with your family and friends to spread the word.</p>

    </section>

    <section class="try-it ">
        <div class="mx-auto mt-5 col-12 col-lg-8 py-5">
            <h4>This was written by graduate students at Northwestern University. If you have any questions or feedback, please feel free to reach out to us.</h4>
            <div class="row mx-auto col-8 text-center">
                <p class="mx-3 col-3 mt-3"><a href="https://www.linkedin.com/in/aristana-scourtas-3a5b85106/" target="blank">Aristana Scourtas</a></p>
                <p class="mx-3 col-3 mt-3"><a href="https://www.linkedin.com/in/schmidtkj/" target="blank">KJ Schmidt</a></p>
                <p class="mx-3 col-3 mt-3"><a href="https://www.linkedin.com/in/victor-s-bursztyn-6bb78026/" target="blank">Victor Bursztyn</a></p>
            </div>

        </div>

    </section>


</body>

</html>